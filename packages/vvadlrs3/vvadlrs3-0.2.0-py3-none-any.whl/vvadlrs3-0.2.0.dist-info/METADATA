Metadata-Version: 2.1
Name: vvadlrs3
Version: 0.2.0
Summary: Library to provide models trained on the VVAD-LRS3 Dataset. The library also contains preprocessing pipelines.
Home-page: https://github.com/adrianlubitz/VVAD
Author: Adrian Lubitz
Author-email: adrianlubitz@gmail.com
License: LGPLv2. Note that the license for the iBUG 300-W dataset which was used for face and lip features excludes commercial use.
Keywords: VVAD LRS3 AI Social robotics
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Topic :: Utilities
Classifier: License :: OSI Approved :: GNU Lesser General Public License v2 (LGPLv2)
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: numpy
Requires-Dist: opencv-contrib-python
Requires-Dist: dlib
Requires-Dist: matplotlib
Requires-Dist: keras (==2.4.3)
Requires-Dist: tensorflow (==2.3.1)
Requires-Dist: tqdm
Requires-Dist: pymongo
Requires-Dist: keras-vggface
Requires-Dist: Keras-Applications
Requires-Dist: pytube
Requires-Dist: ffmpy
Requires-Dist: file-read-backwards

# VVAD-LRS3
Library to provide models trained on the VVAD-LRS3 Dataset. The library also contains preprocessing pipelines.
Applications are Speaker detection in scenarios, where multiple people are in the robot's field of view 
and stare detection for proactive approaches. 

<!-- Add link to the Paper when published -->

# Prerequisites
vvadlrs3 depends on dlib which needs build tools to be installed over pip.
[Here](https://www.pyimagesearch.com/2018/01/22/install-dlib-easy-complete-guide/) is described what is needed.

For Ubuntu you just need to install the following:

```bash
sudo apt-get install build-essential cmake libopenblas-dev liblapack-dev libx11-dev libgtk-3-dev
```

# Install
```bash
pip install vvadlrs3
```

# Data
The models are trained on the VVAD-LRS3 Dataset

<p align="center">
    <img src="sampleVisualization.gif">
    <br>
    <sup>Some samples visualized. Samples with green borders are positive samples, samples with red borders are negative samples</sup>
</p>




